<!DOCTYPE html>
<html class="theme theme-white">
<head>
<meta charset="utf-8">
<title>SciKit-Learn random forest</title>
<link href="https://www.zybuluo.com/static/assets/template-theme-white.css" rel="stylesheet" media="screen">
</head>
<body class="theme theme-white">
<div id="wmd-preview" class="wmd-preview wmd-preview-full-reader"><div class="md-section-divider"></div><div class="md-section-divider"></div><h1 id="scikit-learn-random-forest" data-anchor-id="ewh0">SciKit-Learn random forest</h1><p data-anchor-id="383x"><code>SciKit-Learn</code> <code>随机森林</code> <code>random</code> <code>forest</code><a href="../index.html" style="float:right"><strong>Home</strong></a></p><hr><div class="md-section-divider"></div><h3 id="内容目录" data-anchor-id="2t9e">内容目录</h3><p data-anchor-id="0rwh"><div class="toc"><div class="toc">
<ul>
<li><a href="#scikit-learn-random-forest">SciKit-Learn random forest</a><ul>
<li><ul>
<li><a href="#内容目录">内容目录</a></li>
<li><a href="#随机森林">随机森林</a></li>
<li><a href="#决策树示例">决策树示例</a></li>
<li><a href="#集成学习器随机森林">集成学习器：随机森林</a></li>
<li><a href="#随机森林回归">随机森林回归</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</p><div class="md-section-divider"></div><h3 id="随机森林" data-anchor-id="14su">随机森林</h3><div class="md-section-divider"></div><pre style="" data-anchor-id="4bhz" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pun">%</span><span class="pln">matplotlib inline</span></code></li><li class="L1"><code class="language-python"><span class="kwd">import</span><span class="pln"> numpy </span><span class="kwd">as</span><span class="pln"> np</span></code></li><li class="L2"><code class="language-python"><span class="kwd">import</span><span class="pln"> matplotlib</span><span class="pun">.</span><span class="pln">pyplot </span><span class="kwd">as</span><span class="pln"> plt</span></code></li><li class="L3"><code class="language-python"><span class="kwd">import</span><span class="pln"> seaborn</span><span class="pun">;</span><span class="pln"> </span></code></li><li class="L4"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">linear_model </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">LinearRegression</span></code></li><li class="L5"><code class="language-python"><span class="kwd">from</span><span class="pln"> scipy </span><span class="kwd">import</span><span class="pln"> stats</span></code></li><li class="L6"><code class="language-python"><span class="kwd">import</span><span class="pln"> pylab </span><span class="kwd">as</span><span class="pln"> pl</span></code></li><li class="L7"><code class="language-python"></code></li><li class="L8"><code class="language-python"><span class="pln">seaborn</span><span class="pun">.</span><span class="pln">set</span><span class="pun">()</span></code></li></ol></pre><p data-anchor-id="h97d">随机森林是一种基于决策树的集成学习算法，所以我们从决策树开始。一个简单的决策树示例： <br>
<img src="http://static.zybuluo.com/ronaldhan/3pi5ua3mc6gb5cn8sapxiln7/output_5_0.png" alt="output_5_0.png-40.7kB" title=""> <br>
决策树的关键是找出属性中用来进行分割数据的属性。</p><div class="md-section-divider"></div><h3 id="决策树示例" data-anchor-id="5ffl">决策树示例</h3><div class="md-section-divider"></div><pre style="" data-anchor-id="guak" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">datasets </span><span class="kwd">import</span><span class="pln"> make_blobs</span></code></li><li class="L1"><code class="language-python"></code></li><li class="L2"><code class="language-python"><span class="com"># 生成二维数据</span></code></li><li class="L3"><code class="language-python"><span class="pln">X</span><span class="pun">,</span><span class="pln"> y </span><span class="pun">=</span><span class="pln"> make_blobs</span><span class="pun">(</span><span class="pln">n_samples</span><span class="pun">=</span><span class="lit">300</span><span class="pun">,</span><span class="pln"> centers</span><span class="pun">=</span><span class="lit">4</span><span class="pun">,</span></code></li><li class="L4"><code class="language-python"><span class="pln">                  random_state</span><span class="pun">=</span><span class="lit">0</span><span class="pun">,</span><span class="pln"> cluster_std</span><span class="pun">=</span><span class="lit">1.0</span><span class="pun">)</span></code></li><li class="L5"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">scatter</span><span class="pun">(</span><span class="pln">X</span><span class="pun">[:,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">],</span><span class="pln"> X</span><span class="pun">[:,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">],</span><span class="pln"> c</span><span class="pun">=</span><span class="pln">y</span><span class="pun">,</span><span class="pln"> s</span><span class="pun">=</span><span class="lit">50</span><span class="pun">,</span><span class="pln"> cmap</span><span class="pun">=</span><span class="str">'rainbow'</span><span class="pun">);</span></code></li></ol></pre><p data-anchor-id="kmdq"><img src="http://static.zybuluo.com/ronaldhan/k9mdti55hpzwp41ndm0gqyru/output_7_1.png" alt="output_7_1.png-46.3kB" title=""> <br>
对数据进行决策树分类后结果 <br>
<img src="http://static.zybuluo.com/ronaldhan/awjgwxbsobxkhoqyyg3jl0wi/output_8_0.png" alt="output_8_0.png-53.9kB" title=""> <br>
在生成树的过程中，如果一棵树包含的所有节点类型相同，这棵树就不再分裂，否则需要继续分裂。决策树能够很好地拟合数据，但也容易出现过拟合的现象，这是因为决策树比较灵活，容易学习数据中的噪音而不是数据本身的结构。我们从数据中创建两个子集，分别构建决策树。</p><div class="md-section-divider"></div><pre style="" data-anchor-id="9zrl" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">tree </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">DecisionTreeClassifier</span></code></li><li class="L1"><code class="language-python"><span class="pln">clf </span><span class="pun">=</span><span class="pln"> </span><span class="typ">DecisionTreeClassifier</span><span class="pun">()</span></code></li><li class="L2"><code class="language-python"></code></li><li class="L3"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">figure</span><span class="pun">()</span></code></li><li class="L4"><code class="language-python"><span class="com"># 选择前两百个数据</span></code></li><li class="L5"><code class="language-python"><span class="pln">visualize_tree</span><span class="pun">(</span><span class="pln">clf</span><span class="pun">,</span><span class="pln"> X</span><span class="pun">[:</span><span class="lit">200</span><span class="pun">],</span><span class="pln"> y</span><span class="pun">[:</span><span class="lit">200</span><span class="pun">],</span><span class="pln"> boundaries</span><span class="pun">=</span><span class="kwd">False</span><span class="pun">)</span></code></li><li class="L6"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">figure</span><span class="pun">()</span></code></li><li class="L7"><code class="language-python"><span class="com"># 选择后两百个数据</span></code></li><li class="L8"><code class="language-python"><span class="pln">visualize_tree</span><span class="pun">(</span><span class="pln">clf</span><span class="pun">,</span><span class="pln"> X</span><span class="pun">[-</span><span class="lit">200</span><span class="pun">:],</span><span class="pln"> y</span><span class="pun">[-</span><span class="lit">200</span><span class="pun">:],</span><span class="pln"> boundaries</span><span class="pun">=</span><span class="kwd">False</span><span class="pun">)</span></code></li></ol></pre><p data-anchor-id="w5vf"><img src="http://static.zybuluo.com/ronaldhan/cazuqb6lv36wbitjtah17qr1/output_11_1.png" alt="output_11_1.png-39.7kB" title=""> <br>
<img src="http://static.zybuluo.com/ronaldhan/c0lrb5cbx0ryyjqloc5zy3ta/output_11_3.png" alt="output_11_3.png-40.5kB" title=""> <br>
从两图比较可以看出，两棵决策树的结构完全不同。这就是过拟合的标志：当预测一个新观测点的类型时，预测结果更多反应的是噪声。</p><div class="md-section-divider"></div><h3 id="集成学习器随机森林" data-anchor-id="cvtk">集成学习器：随机森林</h3><p data-anchor-id="h313">解决过拟合的一种方法是使用集成的方法，集成的思路很简单，将多个弱预测模型预测的结果进行平均。集成后的结果会更具有鲁棒性，并且比单独决策树的预测结果提升很多。 <br>
最常使用的集成算法即为随机森林，它使用多个决策树来进行预测。</p><div class="md-section-divider"></div><pre style="" data-anchor-id="5mvw" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">ensemble </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">RandomForestClassifier</span></code></li><li class="L1"><code class="language-python"><span class="com"># 使用100棵树</span></code></li><li class="L2"><code class="language-python"><span class="pln">clf </span><span class="pun">=</span><span class="pln"> </span><span class="typ">RandomForestClassifier</span><span class="pun">(</span><span class="pln">n_estimators</span><span class="pun">=</span><span class="lit">100</span><span class="pun">,</span><span class="pln"> random_state</span><span class="pun">=</span><span class="lit">0</span><span class="pun">,</span><span class="pln"> n_jobs</span><span class="pun">=-</span><span class="lit">1</span><span class="pun">)</span></code></li><li class="L3"><code class="language-python"><span class="pln">visualize_tree</span><span class="pun">(</span><span class="pln">clf</span><span class="pun">,</span><span class="pln"> X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">,</span><span class="pln"> boundaries</span><span class="pun">=</span><span class="kwd">False</span><span class="pun">);</span></code></li></ol></pre><p data-anchor-id="j7om"><img src="http://static.zybuluo.com/ronaldhan/li0t4g3p3w2nqpd9b4zjv9ku/output_16_0.png" alt="output_16_0.png-54.2kB" title=""> <br>
可以从图中看出，分类结果明显改善。</p><div class="md-section-divider"></div><h3 id="随机森林回归" data-anchor-id="74w2">随机森林回归</h3><p data-anchor-id="97fy">随机森林不仅仅可以用在分类，也可以用来对连续数据进行回归，具体可以调用<code>sklearn.ensemble.RandomForestRegressor</code> <br>
先生成样例数据</p><div class="md-section-divider"></div><pre style="" data-anchor-id="oubm" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">ensemble </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">RandomForestRegressor</span></code></li><li class="L1"><code class="language-python"></code></li><li class="L2"><code class="language-python"><span class="pln">x </span><span class="pun">=</span><span class="pln"> </span><span class="lit">10</span><span class="pln"> </span><span class="pun">*</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">random</span><span class="pun">.</span><span class="pln">rand</span><span class="pun">(</span><span class="lit">100</span><span class="pun">)</span></code></li><li class="L3"><code class="language-python"></code></li><li class="L4"><code class="language-python"><span class="kwd">def</span><span class="pln"> model</span><span class="pun">(</span><span class="pln">x</span><span class="pun">,</span><span class="pln"> sigma</span><span class="pun">=</span><span class="lit">0.3</span><span class="pun">):</span></code></li><li class="L5"><code class="language-python"><span class="pln">    fast_oscillation </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">sin</span><span class="pun">(</span><span class="lit">5</span><span class="pln"> </span><span class="pun">*</span><span class="pln"> x</span><span class="pun">)</span></code></li><li class="L6"><code class="language-python"><span class="pln">    slow_oscillation </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">sin</span><span class="pun">(</span><span class="lit">0.5</span><span class="pln"> </span><span class="pun">*</span><span class="pln"> x</span><span class="pun">)</span></code></li><li class="L7"><code class="language-python"><span class="pln">    noise </span><span class="pun">=</span><span class="pln"> sigma </span><span class="pun">*</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">random</span><span class="pun">.</span><span class="pln">randn</span><span class="pun">(</span><span class="pln">len</span><span class="pun">(</span><span class="pln">x</span><span class="pun">))</span></code></li><li class="L8"><code class="language-python"></code></li><li class="L9"><code class="language-python"><span class="pln">    </span><span class="kwd">return</span><span class="pln"> slow_oscillation </span><span class="pun">+</span><span class="pln"> fast_oscillation </span><span class="pun">+</span><span class="pln"> noise</span></code></li><li class="L0"><code class="language-python"></code></li><li class="L1"><code class="language-python"><span class="pln">y </span><span class="pun">=</span><span class="pln"> model</span><span class="pun">(</span><span class="pln">x</span><span class="pun">)</span></code></li><li class="L2"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">errorbar</span><span class="pun">(</span><span class="pln">x</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0.3</span><span class="pun">,</span><span class="pln"> fmt</span><span class="pun">=</span><span class="str">'o'</span><span class="pun">);</span></code></li></ol></pre><p data-anchor-id="4gg4"><img src="http://static.zybuluo.com/ronaldhan/vesramnqqvq1r5s4vess0ygn/output_21_0.png" alt="output_21_0.png-9.1kB" title=""> <br>
使用<code>RandomForestRegressor</code>对数据进行预测</p><div class="md-section-divider"></div><pre style="" data-anchor-id="9nmh" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">xfit </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">linspace</span><span class="pun">(</span><span class="lit">0</span><span class="pun">,</span><span class="pln"> </span><span class="lit">10</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1000</span><span class="pun">)</span></code></li><li class="L1"><code class="language-python"><span class="pln">yfit </span><span class="pun">=</span><span class="pln"> </span><span class="typ">RandomForestRegressor</span><span class="pun">(</span><span class="lit">100</span><span class="pun">).</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">x</span><span class="pun">[:,</span><span class="pln"> </span><span class="kwd">None</span><span class="pun">],</span><span class="pln"> y</span><span class="pun">).</span><span class="pln">predict</span><span class="pun">(</span><span class="pln">xfit</span><span class="pun">[:,</span><span class="pln"> </span><span class="kwd">None</span><span class="pun">])</span></code></li><li class="L2"><code class="language-python"><span class="pln">ytrue </span><span class="pun">=</span><span class="pln"> model</span><span class="pun">(</span><span class="pln">xfit</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">)</span></code></li><li class="L3"><code class="language-python"></code></li><li class="L4"><code class="language-python"><span class="com"># plt.errorbar(x, y, 0.3, fmt='o')</span></code></li><li class="L5"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">plot</span><span class="pun">(</span><span class="pln">xfit</span><span class="pun">,</span><span class="pln"> yfit</span><span class="pun">,</span><span class="pln"> </span><span class="str">'-r'</span><span class="pun">);</span></code></li><li class="L6"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">plot</span><span class="pun">(</span><span class="pln">xfit</span><span class="pun">,</span><span class="pln"> ytrue</span><span class="pun">,</span><span class="pln"> </span><span class="str">'-y'</span><span class="pun">,</span><span class="pln"> alpha</span><span class="pun">=</span><span class="lit">0.5</span><span class="pun">);</span></code></li></ol></pre><p data-anchor-id="xu6z"><img src="http://static.zybuluo.com/ronaldhan/kd5zahyeh1n36o27a4oz0duz/output_22_0.png" alt="output_22_0.png-39kB" title=""> <br>
从图中可以看出，非参数化的随机森林模型足够灵活，用于拟合复杂的数据。</p><p data-anchor-id="aqeq">随机森林模型不适用的场景：</p><ul data-anchor-id="yjji">
<li>y值有较多的0，较少的1</li>
<li>类似图片之类的结构化数据，用神经网络更合适</li>
<li>数据集较小，容易导致过拟合</li>
<li>高维数据，线性模型更适合</li>
</ul></div>
</body>
</html>