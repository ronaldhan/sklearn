<!DOCTYPE html>
<html class="theme theme-white">
<head>
<meta charset="utf-8">
<title>SciKit-Learn 模型验证</title>
<link href="https://www.zybuluo.com/static/assets/template-theme-white.css" rel="stylesheet" media="screen">
</head>
<body class="theme theme-white">
<div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px none; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_SVG_Hidden"></div><svg><defs id="MathJax_SVG_glyphs"><path d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" stroke-width="1" id="MJMAIN-33"></path><path d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" stroke-width="1" id="MJMAIN-34"></path><path d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z" stroke-width="1" id="MJMATHI-64"></path></defs></svg></div><div id="wmd-preview" class="wmd-preview wmd-preview-full-reader"><div class="md-section-divider"></div><div class="md-section-divider"></div><h1 id="scikit-learn-模型验证" data-anchor-id="qhfs">SciKit-Learn 模型验证</h1><p data-anchor-id="vipd"><code>SciKit-Learn</code> <code>validation</code><a href="../index.html" style="float:right"><strong>Home</strong></a></p><hr><div class="md-section-divider"></div><h3 id="内容目录" data-anchor-id="tgrr">内容目录</h3><p data-anchor-id="modb"><div class="toc"><div class="toc">
<ul>
<li><a href="#scikit-learn-模型验证">SciKit-Learn 模型验证</a><ul>
<li><ul>
<li><a href="#内容目录">内容目录</a></li>
<li><a href="#模型验证">模型验证</a></li>
<li><a href="#验证数据集">验证数据集</a></li>
<li><a href="#交叉验证">交叉验证</a></li>
<li><a href="#k折交叉验证">k折交叉验证</a></li>
<li><a href="#过拟合欠拟合和模型选择">过拟合、欠拟合和模型选择</a></li>
<li><a href="#偏差-方差均衡">偏差-方差均衡</a></li>
<li><a href="#通过验证曲线来发现模型是否过拟合">通过验证曲线来发现模型是否过拟合</a></li>
<li><a href="#通过学习曲线来判断训练数据是否充足">通过学习曲线来判断训练数据是否充足</a></li>
<li><a href="#总结">总结</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</p><div class="md-section-divider"></div><h3 id="模型验证" data-anchor-id="0vr2">模型验证</h3><div class="md-section-divider"></div><pre style="" data-anchor-id="hihv" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> __future__ </span><span class="kwd">import</span><span class="pln"> print_function</span><span class="pun">,</span><span class="pln"> division</span></code></li><li class="L1"><code class="language-python"></code></li><li class="L2"><code class="language-python"><span class="pun">%</span><span class="pln">matplotlib inline</span></code></li><li class="L3"><code class="language-python"><span class="kwd">import</span><span class="pln"> numpy </span><span class="kwd">as</span><span class="pln"> np</span></code></li><li class="L4"><code class="language-python"><span class="kwd">import</span><span class="pln"> matplotlib</span><span class="pun">.</span><span class="pln">pyplot </span><span class="kwd">as</span><span class="pln"> plt</span></code></li><li class="L5"><code class="language-python"></code></li><li class="L6"><code class="language-python"><span class="kwd">import</span><span class="pln"> seaborn </span><span class="kwd">as</span><span class="pln"> sns</span><span class="pun">;</span><span class="pln"> sns</span><span class="pun">.</span><span class="pln">set</span><span class="pun">()</span></code></li></ol></pre><p data-anchor-id="nf5f">机器学习最重要的工作之一就是模型验证：检查模型对于数据集拟合程度的好坏。在进行验证时，有几点需要注意，以knn算法为例。</p><div class="md-section-divider"></div><pre style="" data-anchor-id="as57" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="com"># 样例数据</span></code></li><li class="L1"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">datasets </span><span class="kwd">import</span><span class="pln"> load_digits</span></code></li><li class="L2"><code class="language-python"><span class="pln">digits </span><span class="pun">=</span><span class="pln"> load_digits</span><span class="pun">()</span></code></li><li class="L3"><code class="language-python"><span class="pln">X </span><span class="pun">=</span><span class="pln"> digits</span><span class="pun">.</span><span class="pln">data</span></code></li><li class="L4"><code class="language-python"><span class="pln">y </span><span class="pun">=</span><span class="pln"> digits</span><span class="pun">.</span><span class="pln">target</span></code></li></ol></pre><div class="md-section-divider"></div><pre style="" data-anchor-id="jj88" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">neighbors </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">KNeighborsClassifier</span></code></li><li class="L1"><code class="language-python"><span class="pln">knn </span><span class="pun">=</span><span class="pln"> </span><span class="typ">KNeighborsClassifier</span><span class="pun">(</span><span class="pln">n_neighbors</span><span class="pun">=</span><span class="lit">1</span><span class="pun">)</span></code></li><li class="L2"><code class="language-python"><span class="pln">knn</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">)</span></code></li></ol></pre><pre data-anchor-id="vt3a"><code># 模型属性
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_neighbors=1, p=2, weights='uniform')
</code></pre><p data-anchor-id="mdky">接下来我们利用这个模型来预测</p><div class="md-section-divider"></div><pre style="" data-anchor-id="t8c1" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">y_pred </span><span class="pun">=</span><span class="pln"> knn</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="pln">X</span><span class="pun">)</span></code></li><li class="L1"><code class="language-python"><span class="kwd">print</span><span class="pun">(</span><span class="str">"{0} / {1} correct"</span><span class="pun">.</span><span class="pln">format</span><span class="pun">(</span><span class="pln">np</span><span class="pun">.</span><span class="pln">sum</span><span class="pun">(</span><span class="pln">y </span><span class="pun">==</span><span class="pln"> y_pred</span><span class="pun">),</span><span class="pln"> len</span><span class="pun">(</span><span class="pln">y</span><span class="pun">)))</span></code></li></ol></pre><pre data-anchor-id="rt22"><code>1797 / 1797 correct
</code></pre><p data-anchor-id="0o25">可以看到所有的预测结果与原结果相同，准确率100%，但这样的模型存在什么样的问题呢？</p><div class="md-section-divider"></div><h3 id="验证数据集" data-anchor-id="8gcm">验证数据集</h3><p data-anchor-id="vqbz">以上模型的错误之处在于验证模型时使用了和训练模型相同的数据集。这通常而言并不是一个好主意，往往会导致模型的过拟合。 <br>
更好的方式是，在训练模型之前把数据集划分为训练数据集和验证数据集。</p><div class="md-section-divider"></div><pre style="" data-anchor-id="xrm1" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">cross_validation </span><span class="kwd">import</span><span class="pln"> train_test_split</span></code></li><li class="L1"><code class="language-python"><span class="pln">X_train</span><span class="pun">,</span><span class="pln"> X_test</span><span class="pun">,</span><span class="pln"> y_train</span><span class="pun">,</span><span class="pln"> y_test </span><span class="pun">=</span><span class="pln"> train_test_split</span><span class="pun">(</span><span class="pln">X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">)</span></code></li><li class="L2"><code class="language-python"><span class="pln">X_train</span><span class="pun">.</span><span class="pln">shape</span><span class="pun">,</span><span class="pln"> X_test</span><span class="pun">.</span><span class="pln">shape</span></code></li></ol></pre><pre data-anchor-id="gptf"><code>((1347L, 64L), (450L, 64L))
</code></pre><p data-anchor-id="i13h">现在我们在训练数据集上训练模型，使用验证数据集验证模型。</p><div class="md-section-divider"></div><pre style="" data-anchor-id="endp" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">knn </span><span class="pun">=</span><span class="pln"> </span><span class="typ">KNeighborsClassifier</span><span class="pun">(</span><span class="pln">n_neighbors</span><span class="pun">=</span><span class="lit">1</span><span class="pun">)</span></code></li><li class="L1"><code class="language-python"><span class="pln">knn</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X_train</span><span class="pun">,</span><span class="pln"> y_train</span><span class="pun">)</span></code></li><li class="L2"><code class="language-python"><span class="pln">y_pred </span><span class="pun">=</span><span class="pln"> knn</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="pln">X_test</span><span class="pun">)</span></code></li><li class="L3"><code class="language-python"><span class="kwd">print</span><span class="pun">(</span><span class="str">"{0} / {1} correct"</span><span class="pun">.</span><span class="pln">format</span><span class="pun">(</span><span class="pln">np</span><span class="pun">.</span><span class="pln">sum</span><span class="pun">(</span><span class="pln">y_test </span><span class="pun">==</span><span class="pln"> y_pred</span><span class="pun">),</span><span class="pln"> len</span><span class="pun">(</span><span class="pln">y_test</span><span class="pun">)))</span></code></li></ol></pre><pre data-anchor-id="gwaq"><code>443 / 450 correct
</code></pre><p data-anchor-id="lefe">现在我们对于模型有了一个更准确的评估。衡量模型的一个指标是<strong>正确率得分</strong>，在scikit-learn中可以使用以下方法进行计算。</p><div class="md-section-divider"></div><pre style="" data-anchor-id="6d0y" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">metrics </span><span class="kwd">import</span><span class="pln"> accuracy_score</span></code></li><li class="L1"><code class="language-python"><span class="pln">accuracy_score</span><span class="pun">(</span><span class="pln">y_test</span><span class="pun">,</span><span class="pln"> y_pred</span><span class="pun">)</span></code></li></ol></pre><pre data-anchor-id="omzb"><code>0.97333333333333338
</code></pre><p data-anchor-id="8wot">也可以使用<code>model.score</code>方法来计算</p><div class="md-section-divider"></div><pre style="" data-anchor-id="85ng" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">knn</span><span class="pun">.</span><span class="pln">score</span><span class="pun">(</span><span class="pln">X_test</span><span class="pun">,</span><span class="pln"> y_test</span><span class="pun">)</span></code></li></ol></pre><pre data-anchor-id="hj51"><code>0.97333333333333338
</code></pre><p data-anchor-id="haav">利用这个指标，我们可以观察最近邻数量变化时模型变化情况</p><div class="md-section-divider"></div><pre style="" data-anchor-id="53y1" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">for</span><span class="pln"> n_neighbors </span><span class="kwd">in</span><span class="pln"> </span><span class="pun">[</span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">5</span><span class="pun">,</span><span class="pln"> </span><span class="lit">10</span><span class="pun">,</span><span class="pln"> </span><span class="lit">20</span><span class="pun">,</span><span class="pln"> </span><span class="lit">30</span><span class="pun">]:</span></code></li><li class="L1"><code class="language-python"><span class="pln">    knn </span><span class="pun">=</span><span class="pln"> </span><span class="typ">KNeighborsClassifier</span><span class="pun">(</span><span class="pln">n_neighbors</span><span class="pun">)</span></code></li><li class="L2"><code class="language-python"><span class="pln">    knn</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X_train</span><span class="pun">,</span><span class="pln"> y_train</span><span class="pun">)</span></code></li><li class="L3"><code class="language-python"><span class="pln">    </span><span class="kwd">print</span><span class="pun">(</span><span class="pln">n_neighbors</span><span class="pun">,</span><span class="pln"> knn</span><span class="pun">.</span><span class="pln">score</span><span class="pun">(</span><span class="pln">X_test</span><span class="pun">,</span><span class="pln"> y_test</span><span class="pun">))</span></code></li></ol></pre><pre data-anchor-id="giyh"><code>1 0.973333333333
5 0.982222222222
10 0.971111111111
20 0.955555555556
30 0.96
</code></pre><p data-anchor-id="3bnd">在这个示例中可以观察到，选择较小的近邻数是较优选择。</p><div class="md-section-divider"></div><h3 id="交叉验证" data-anchor-id="alee">交叉验证</h3><p data-anchor-id="cugg">简单划分训练数据和验证数据集的一个问题是：模型丢失了部分数据集中包含的信息。比如，在上面的例子中我们只使用了<span class="MathJax_Preview"></span><span aria-readonly="true" role="textbox" id="MathJax-Element-40-Frame" class="MathJax_SVG" style="font-size: 100%; display: inline-block;"><svg viewBox="0 -907.7986235655877 713.906943983867 1308.52617931931" style="width: 1.667ex; height: 3ex; vertical-align: -1ex; margin: 1px 0px;" xmlns:xlink="http://www.w3.org/1999/xlink"><g transform="matrix(1 0 0 -1 0 0)" stroke-width="0" fill="black" stroke="black"><g transform="translate(120,0)"><rect y="220" x="0" height="60" width="473" stroke="none"></rect><use y="588" x="84" xlink:href="#MJMAIN-33" transform="scale(0.7071067811865476)"></use><use y="-537" x="84" xlink:href="#MJMAIN-34" transform="scale(0.7071067811865476)"></use></g></g></svg></span><script id="MathJax-Element-40" type="math/tex">\frac{3} {4}</script>的数据用来训练模型，其他的数据用来验证。一个可行的解决方法是使用<strong>2折验证(2-fold cross-validation)</strong>，具体而言，将数据分为两半，将其中一半数据做训练数据集，另一半做验证数据集，执行两次验证。</p><div class="md-section-divider"></div><pre style="" data-anchor-id="g6rj" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">X1</span><span class="pun">,</span><span class="pln"> X2</span><span class="pun">,</span><span class="pln"> y1</span><span class="pun">,</span><span class="pln"> y2 </span><span class="pun">=</span><span class="pln"> train_test_split</span><span class="pun">(</span><span class="pln">X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">,</span><span class="pln"> test_size</span><span class="pun">=</span><span class="lit">0.5</span><span class="pun">,</span><span class="pln"> random_state</span><span class="pun">=</span><span class="lit">0</span><span class="pun">)</span></code></li><li class="L1"><code class="language-python"><span class="pln">X1</span><span class="pun">.</span><span class="pln">shape</span><span class="pun">,</span><span class="pln"> X2</span><span class="pun">.</span><span class="pln">shape</span></code></li></ol></pre><pre data-anchor-id="zjwu"><code>((898L, 64L), (899L, 64L))
</code></pre><div class="md-section-divider"></div><pre style="" data-anchor-id="o38t" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">print</span><span class="pun">(</span><span class="typ">KNeighborsClassifier</span><span class="pun">(</span><span class="lit">1</span><span class="pun">).</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X2</span><span class="pun">,</span><span class="pln"> y2</span><span class="pun">).</span><span class="pln">score</span><span class="pun">(</span><span class="pln">X1</span><span class="pun">,</span><span class="pln"> y1</span><span class="pun">))</span></code></li><li class="L1"><code class="language-python"><span class="kwd">print</span><span class="pun">(</span><span class="typ">KNeighborsClassifier</span><span class="pun">(</span><span class="lit">1</span><span class="pun">).</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X1</span><span class="pun">,</span><span class="pln"> y1</span><span class="pun">).</span><span class="pln">score</span><span class="pun">(</span><span class="pln">X2</span><span class="pun">,</span><span class="pln"> y2</span><span class="pun">))</span></code></li></ol></pre><pre data-anchor-id="js7t"><code>0.983296213808
0.982202447164
</code></pre><p data-anchor-id="n0ci">在scikit-learn中进行两折验证</p><div class="md-section-divider"></div><pre style="" data-anchor-id="xw31" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">cross_validation </span><span class="kwd">import</span><span class="pln"> cross_val_score</span></code></li><li class="L1"><code class="language-python"><span class="com"># 函数中cv验证数据集生成策略，参数可选</span></code></li><li class="L2"><code class="language-python"><span class="com"># 为none时，默认使用3折验证</span></code></li><li class="L3"><code class="language-python"><span class="com"># 为int时，为验证数据集的折数</span></code></li><li class="L4"><code class="language-python"><span class="pln">cv </span><span class="pun">=</span><span class="pln"> cross_val_score</span><span class="pun">(</span><span class="typ">KNeighborsClassifier</span><span class="pun">(</span><span class="lit">1</span><span class="pun">),</span><span class="pln"> X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">,</span><span class="pln"> cv</span><span class="pun">=</span><span class="lit">10</span><span class="pun">)</span></code></li><li class="L5"><code class="language-python"><span class="pln">cv</span><span class="pun">.</span><span class="pln">mean</span><span class="pun">()</span></code></li></ol></pre><pre data-anchor-id="issr"><code>0.97614938602520218
</code></pre><div class="md-section-divider"></div><h3 id="k折交叉验证" data-anchor-id="sq06">k折交叉验证</h3><p data-anchor-id="rbo9">如上<code>cross_val_score</code>函数，选择其他折数</p><div class="md-section-divider"></div><pre style="" data-anchor-id="qh33" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">cross_val_score</span><span class="pun">(</span><span class="typ">KNeighborsClassifier</span><span class="pun">(</span><span class="lit">1</span><span class="pun">),</span><span class="pln"> X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">,</span><span class="pln"> cv</span><span class="pun">=</span><span class="lit">10</span><span class="pun">)</span></code></li></ol></pre><pre data-anchor-id="36ep"><code>array([ 0.93513514,  0.99453552,  0.97237569,  0.98888889,  0.96089385,
        0.98882682,  0.99441341,  0.98876404,  0.97175141,  0.96590909])
</code></pre><div class="md-section-divider"></div><h3 id="过拟合欠拟合和模型选择" data-anchor-id="booe">过拟合、欠拟合和模型选择</h3><p data-anchor-id="w988">在使用机器学习模型时，以下问题是需要思考的：</p><ul data-anchor-id="i6qe">
<li>使用简单模型还是复杂模型？</li>
<li>是否需要为数据增加特征？</li>
<li>是否使用更多训练数据？</li>
</ul><p data-anchor-id="crrr">对以上问题的回答可能是有违直觉的，实际中，有时使用复杂模型会得到更差的结果，有时增加训练数据并不能提升结果。能否找到提升模型的影响因素是区别成功的机器学习和失败的机器学习的重要标志。</p><div class="md-section-divider"></div><h3 id="偏差-方差均衡" data-anchor-id="c4mk">偏差-方差均衡</h3><p data-anchor-id="bqoa">我们利用回归模型来展示模型偏差和方差之间的均衡。首先我们创建模拟数据：</p><div class="md-section-divider"></div><pre style="" data-anchor-id="5hjp" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">def</span><span class="pln"> test_func</span><span class="pun">(</span><span class="pln">x</span><span class="pun">,</span><span class="pln"> err</span><span class="pun">=</span><span class="lit">0.5</span><span class="pun">):</span></code></li><li class="L1"><code class="language-python"><span class="pln">    y </span><span class="pun">=</span><span class="pln"> </span><span class="lit">10</span><span class="pln"> </span><span class="pun">-</span><span class="pln"> </span><span class="lit">1.</span><span class="pln"> </span><span class="pun">/</span><span class="pln"> </span><span class="pun">(</span><span class="pln">x </span><span class="pun">+</span><span class="pln"> </span><span class="lit">0.1</span><span class="pun">)</span></code></li><li class="L2"><code class="language-python"><span class="pln">    </span><span class="kwd">if</span><span class="pln"> err </span><span class="pun">&gt;</span><span class="pln"> </span><span class="lit">0</span><span class="pun">:</span></code></li><li class="L3"><code class="language-python"><span class="pln">        y </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">random</span><span class="pun">.</span><span class="pln">normal</span><span class="pun">(</span><span class="pln">y</span><span class="pun">,</span><span class="pln"> err</span><span class="pun">)</span></code></li><li class="L4"><code class="language-python"><span class="pln">    </span><span class="kwd">return</span><span class="pln"> y</span></code></li><li class="L5"><code class="language-python"></code></li><li class="L6"><code class="language-python"><span class="kwd">def</span><span class="pln"> make_data</span><span class="pun">(</span><span class="pln">N</span><span class="pun">=</span><span class="lit">40</span><span class="pun">,</span><span class="pln"> error</span><span class="pun">=</span><span class="lit">1.0</span><span class="pun">,</span><span class="pln"> random_seed</span><span class="pun">=</span><span class="lit">1</span><span class="pun">):</span></code></li><li class="L7"><code class="language-python"><span class="pln">    </span><span class="com"># randomly sample the data</span></code></li><li class="L8"><code class="language-python"><span class="pln">    np</span><span class="pun">.</span><span class="pln">random</span><span class="pun">.</span><span class="pln">seed</span><span class="pun">(</span><span class="lit">1</span><span class="pun">)</span></code></li><li class="L9"><code class="language-python"><span class="pln">    X </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">random</span><span class="pun">.</span><span class="pln">random</span><span class="pun">(</span><span class="pln">N</span><span class="pun">)[:,</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">newaxis</span><span class="pun">]</span></code></li><li class="L0"><code class="language-python"><span class="pln">    y </span><span class="pun">=</span><span class="pln"> test_func</span><span class="pun">(</span><span class="pln">X</span><span class="pun">.</span><span class="pln">ravel</span><span class="pun">(),</span><span class="pln"> error</span><span class="pun">)</span></code></li><li class="L1"><code class="language-python"></code></li><li class="L2"><code class="language-python"><span class="pln">    </span><span class="kwd">return</span><span class="pln"> X</span><span class="pun">,</span><span class="pln"> y</span></code></li></ol></pre><div class="md-section-divider"></div><pre style="" data-anchor-id="qr7e" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">X</span><span class="pun">,</span><span class="pln"> y </span><span class="pun">=</span><span class="pln"> make_data</span><span class="pun">(</span><span class="lit">40</span><span class="pun">,</span><span class="pln"> error</span><span class="pun">=</span><span class="lit">1</span><span class="pun">)</span></code></li><li class="L1"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">scatter</span><span class="pun">(</span><span class="pln">X</span><span class="pun">.</span><span class="pln">ravel</span><span class="pun">(),</span><span class="pln"> y</span><span class="pun">);</span></code></li></ol></pre><p data-anchor-id="wce7"><img src="http://static.zybuluo.com/ronaldhan/ov8rns86ry4tkzig5nbw2j7p/output_37_1.png" alt="output_37_1.png-6.7kB" title=""> <br>
我们对模拟数据进行回归，使用scikit-learn内置回归模型</p><div class="md-section-divider"></div><pre style="" data-anchor-id="qd5y" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">X_test </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">linspace</span><span class="pun">(-</span><span class="lit">0.1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1.1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">500</span><span class="pun">)[:,</span><span class="pln"> </span><span class="kwd">None</span><span class="pun">]</span></code></li><li class="L1"><code class="language-python"></code></li><li class="L2"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">linear_model </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">LinearRegression</span></code></li><li class="L3"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">metrics </span><span class="kwd">import</span><span class="pln"> mean_squared_error</span></code></li><li class="L4"><code class="language-python"><span class="pln">model </span><span class="pun">=</span><span class="pln"> </span><span class="typ">LinearRegression</span><span class="pun">()</span></code></li><li class="L5"><code class="language-python"><span class="pln">model</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">)</span></code></li><li class="L6"><code class="language-python"><span class="pln">y_test </span><span class="pun">=</span><span class="pln"> model</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="pln">X_test</span><span class="pun">)</span></code></li><li class="L7"><code class="language-python"></code></li><li class="L8"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">scatter</span><span class="pun">(</span><span class="pln">X</span><span class="pun">.</span><span class="pln">ravel</span><span class="pun">(),</span><span class="pln"> y</span><span class="pun">)</span></code></li><li class="L9"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">plot</span><span class="pun">(</span><span class="pln">X_test</span><span class="pun">.</span><span class="pln">ravel</span><span class="pun">(),</span><span class="pln"> y_test</span><span class="pun">)</span></code></li><li class="L0"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">title</span><span class="pun">(</span><span class="str">"mean squared error: {0:.3g}"</span><span class="pun">.</span><span class="pln">format</span><span class="pun">(</span><span class="pln">mean_squared_error</span><span class="pun">(</span><span class="pln">model</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="pln">X</span><span class="pun">),</span><span class="pln"> y</span><span class="pun">)));</span></code></li><li class="L1"><code class="language-python"><span class="pun">```![</span><span class="pln">output_39_0</span><span class="pun">.</span><span class="pln">png</span><span class="pun">-</span><span class="lit">13.1kB</span><span class="pun">][</span><span class="lit">2</span><span class="pun">]</span></code></li><li class="L2"><code class="language-python"><span class="pun">模型使用直线来拟合数据，但从图像中可以观察到，直线并不是一个合适的选择，这就是说我们的模型是**有偏差的(</span><span class="pln">biased</span><span class="pun">)**，或者说模型处于**欠拟合**状态。</span></code></li><li class="L3"><code class="language-python"><span class="pun">为了提高模型拟合的精度，我们需要增加模型的复杂度，用多项式来拟合数据。</span></code></li><li class="L4"><code class="language-python"></code></li><li class="L5"><code class="language-python"></code></li><li class="L6"><code class="language-python"><span class="pun">&lt;</span><span class="pln">div </span><span class="kwd">class</span><span class="pun">=</span><span class="str">"md-section-divider"</span><span class="pun">&gt;&lt;/</span><span class="pln">div</span><span class="pun">&gt;</span></code></li><li class="L7"><code class="language-python"></code></li><li class="L8"><code class="language-python"><span class="pun">```</span><span class="pln">python</span></code></li><li class="L9"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">preprocessing </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">PolynomialFeatures</span></code></li><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">linear_model </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">LinearRegression</span></code></li><li class="L1"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">pipeline </span><span class="kwd">import</span><span class="pln"> make_pipeline</span></code></li><li class="L2"><code class="language-python"></code></li><li class="L3"><code class="language-python"><span class="kwd">def</span><span class="pln"> </span><span class="typ">PolynomialRegression</span><span class="pun">(</span><span class="pln">degree</span><span class="pun">=</span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="pun">**</span><span class="pln">kwargs</span><span class="pun">):</span></code></li><li class="L4"><code class="language-python"><span class="pln">    </span><span class="kwd">return</span><span class="pln"> make_pipeline</span><span class="pun">(</span><span class="typ">PolynomialFeatures</span><span class="pun">(</span><span class="pln">degree</span><span class="pun">),</span></code></li><li class="L5"><code class="language-python"><span class="pln">                         </span><span class="typ">LinearRegression</span><span class="pun">(**</span><span class="pln">kwargs</span><span class="pun">))</span></code></li></ol></pre><div class="md-section-divider"></div><pre style="" data-anchor-id="ylpr" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="com"># 使用2次曲线来拟合</span></code></li><li class="L1"><code class="language-python"><span class="pln">model </span><span class="pun">=</span><span class="pln"> </span><span class="typ">PolynomialRegression</span><span class="pun">(</span><span class="lit">2</span><span class="pun">)</span></code></li><li class="L2"><code class="language-python"><span class="pln">model</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">)</span></code></li><li class="L3"><code class="language-python"><span class="pln">y_test </span><span class="pun">=</span><span class="pln"> model</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="pln">X_test</span><span class="pun">)</span></code></li><li class="L4"><code class="language-python"></code></li><li class="L5"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">scatter</span><span class="pun">(</span><span class="pln">X</span><span class="pun">.</span><span class="pln">ravel</span><span class="pun">(),</span><span class="pln"> y</span><span class="pun">)</span></code></li><li class="L6"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">plot</span><span class="pun">(</span><span class="pln">X_test</span><span class="pun">.</span><span class="pln">ravel</span><span class="pun">(),</span><span class="pln"> y_test</span><span class="pun">)</span></code></li><li class="L7"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">title</span><span class="pun">(</span><span class="str">"mean squared error: {0:.3g}"</span><span class="pun">.</span><span class="pln">format</span><span class="pun">(</span><span class="pln">mean_squared_error</span><span class="pun">(</span><span class="pln">model</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="pln">X</span><span class="pun">),</span><span class="pln"> y</span><span class="pun">)));</span></code></li></ol></pre><p data-anchor-id="qsid"><img src="http://static.zybuluo.com/ronaldhan/g4ri9mlcmsmscmfgjbujv5ni/output_43_0.png" alt="output_43_0.png-14.7kB" title=""> <br>
可以看到模型的MSE下降，说明模型的拟合质量提高，但是我们进一步增加模型的复杂度会不会提升模型质量呢？</p><div class="md-section-divider"></div><pre style="" data-anchor-id="krcb" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">model </span><span class="pun">=</span><span class="pln"> </span><span class="typ">PolynomialRegression</span><span class="pun">(</span><span class="lit">30</span><span class="pun">)</span></code></li><li class="L1"><code class="language-python"><span class="pln">model</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">)</span></code></li><li class="L2"><code class="language-python"><span class="pln">y_test </span><span class="pun">=</span><span class="pln"> model</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="pln">X_test</span><span class="pun">)</span></code></li><li class="L3"><code class="language-python"></code></li><li class="L4"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">scatter</span><span class="pun">(</span><span class="pln">X</span><span class="pun">.</span><span class="pln">ravel</span><span class="pun">(),</span><span class="pln"> y</span><span class="pun">)</span></code></li><li class="L5"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">plot</span><span class="pun">(</span><span class="pln">X_test</span><span class="pun">.</span><span class="pln">ravel</span><span class="pun">(),</span><span class="pln"> y_test</span><span class="pun">)</span></code></li><li class="L6"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">title</span><span class="pun">(</span><span class="str">"mean squared error: {0:.3g}"</span><span class="pun">.</span><span class="pln">format</span><span class="pun">(</span><span class="pln">mean_squared_error</span><span class="pun">(</span><span class="pln">model</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="pln">X</span><span class="pun">),</span><span class="pln"> y</span><span class="pun">)))</span></code></li><li class="L7"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">ylim</span><span class="pun">(-</span><span class="lit">4</span><span class="pun">,</span><span class="pln"> </span><span class="lit">14</span><span class="pun">);</span></code></li></ol></pre><p data-anchor-id="rtgi"><img src="http://static.zybuluo.com/ronaldhan/w1k42a3ml0edyjyttx3nhkh8/output_45_0.png" alt="output_45_0.png-21kB" title=""> <br>
可以看到，拟合出来的曲线形状怪异，虽然MSE下降，但曲线并不能真正反映数据集的分布，而是包含了噪音。这类模型被称为<strong>高方差模型(high-variance model)</strong>，或者说模型处于<strong>过拟合</strong>状态。</p><div class="md-section-divider"></div><h3 id="通过验证曲线来发现模型是否过拟合" data-anchor-id="lqfg">通过验证曲线来发现模型是否过拟合</h3><p data-anchor-id="ya7x">通过以上的例子可以发现，仅仅计算模型的MSE并不够，我们可以使用<strong>交叉验证</strong>来更好地衡量模型的质量。</p><div class="md-section-divider"></div><pre style="" data-anchor-id="7ujo" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">X</span><span class="pun">,</span><span class="pln"> y </span><span class="pun">=</span><span class="pln"> make_data</span><span class="pun">(</span><span class="lit">120</span><span class="pun">,</span><span class="pln"> error</span><span class="pun">=</span><span class="lit">1.0</span><span class="pun">)</span></code></li><li class="L1"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">scatter</span><span class="pun">(</span><span class="pln">X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">);</span></code></li></ol></pre><p data-anchor-id="kozu"><img src="http://static.zybuluo.com/ronaldhan/3vr2y3lptyziko6n54f22138/output_50_0.png" alt="output_50_0.png-8.7kB" title=""></p><div class="md-section-divider"></div><pre style="" data-anchor-id="kfnq" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">learning_curve </span><span class="kwd">import</span><span class="pln"> validation_curve</span></code></li><li class="L1"><code class="language-python"></code></li><li class="L2"><code class="language-python"><span class="kwd">def</span><span class="pln"> rms_error</span><span class="pun">(</span><span class="pln">model</span><span class="pun">,</span><span class="pln"> X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">):</span></code></li><li class="L3"><code class="language-python"><span class="pln">    y_pred </span><span class="pun">=</span><span class="pln"> model</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="pln">X</span><span class="pun">)</span></code></li><li class="L4"><code class="language-python"><span class="pln">    </span><span class="kwd">return</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">sqrt</span><span class="pun">(</span><span class="pln">np</span><span class="pun">.</span><span class="pln">mean</span><span class="pun">((</span><span class="pln">y </span><span class="pun">-</span><span class="pln"> y_pred</span><span class="pun">)</span><span class="pln"> </span><span class="pun">**</span><span class="pln"> </span><span class="lit">2</span><span class="pun">))</span></code></li><li class="L5"><code class="language-python"></code></li><li class="L6"><code class="language-python"><span class="pln">degree </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">arange</span><span class="pun">(</span><span class="lit">0</span><span class="pun">,</span><span class="pln"> </span><span class="lit">18</span><span class="pun">)</span></code></li><li class="L7"><code class="language-python"><span class="pln">val_train</span><span class="pun">,</span><span class="pln"> val_test </span><span class="pun">=</span><span class="pln"> validation_curve</span><span class="pun">(</span><span class="typ">PolynomialRegression</span><span class="pun">(),</span><span class="pln"> X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">,</span><span class="pln"> </span><span class="str">'polynomialfeatures__degree'</span><span class="pun">,</span><span class="pln"> degree</span><span class="pun">,</span><span class="pln"> cv</span><span class="pun">=</span><span class="lit">7</span><span class="pun">,</span><span class="pln"> scoring</span><span class="pun">=</span><span class="pln">rms_error</span><span class="pun">)</span></code></li></ol></pre><p data-anchor-id="rund">将不同自由度的模型训练误差用曲线画出来</p><div class="md-section-divider"></div><pre style="" data-anchor-id="oc4u" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">def</span><span class="pln"> plot_with_err</span><span class="pun">(</span><span class="pln">x</span><span class="pun">,</span><span class="pln"> data</span><span class="pun">,</span><span class="pln"> </span><span class="pun">**</span><span class="pln">kwargs</span><span class="pun">):</span></code></li><li class="L1"><code class="language-python"><span class="pln">    mu</span><span class="pun">,</span><span class="pln"> std </span><span class="pun">=</span><span class="pln"> data</span><span class="pun">.</span><span class="pln">mean</span><span class="pun">(</span><span class="lit">1</span><span class="pun">),</span><span class="pln"> data</span><span class="pun">.</span><span class="pln">std</span><span class="pun">(</span><span class="lit">1</span><span class="pun">)</span></code></li><li class="L2"><code class="language-python"><span class="pln">    lines </span><span class="pun">=</span><span class="pln"> plt</span><span class="pun">.</span><span class="pln">plot</span><span class="pun">(</span><span class="pln">x</span><span class="pun">,</span><span class="pln"> mu</span><span class="pun">,</span><span class="pln"> </span><span class="str">'-'</span><span class="pun">,</span><span class="pln"> </span><span class="pun">**</span><span class="pln">kwargs</span><span class="pun">)</span></code></li><li class="L3"><code class="language-python"><span class="pln">    plt</span><span class="pun">.</span><span class="pln">fill_between</span><span class="pun">(</span><span class="pln">x</span><span class="pun">,</span><span class="pln"> mu </span><span class="pun">-</span><span class="pln"> std</span><span class="pun">,</span><span class="pln"> mu </span><span class="pun">+</span><span class="pln"> std</span><span class="pun">,</span><span class="pln"> edgecolor</span><span class="pun">=</span><span class="str">'none'</span><span class="pun">,</span></code></li><li class="L4"><code class="language-python"><span class="pln">                     facecolor</span><span class="pun">=</span><span class="pln">lines</span><span class="pun">[</span><span class="lit">0</span><span class="pun">].</span><span class="pln">get_color</span><span class="pun">(),</span><span class="pln"> alpha</span><span class="pun">=</span><span class="lit">0.2</span><span class="pun">)</span></code></li><li class="L5"><code class="language-python"></code></li><li class="L6"><code class="language-python"><span class="pln">plot_with_err</span><span class="pun">(</span><span class="pln">degree</span><span class="pun">,</span><span class="pln"> val_train</span><span class="pun">,</span><span class="pln"> label</span><span class="pun">=</span><span class="str">'training scores'</span><span class="pun">)</span></code></li><li class="L7"><code class="language-python"><span class="pln">plot_with_err</span><span class="pun">(</span><span class="pln">degree</span><span class="pun">,</span><span class="pln"> val_test</span><span class="pun">,</span><span class="pln"> label</span><span class="pun">=</span><span class="str">'validation scores'</span><span class="pun">)</span></code></li><li class="L8"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">xlabel</span><span class="pun">(</span><span class="str">'degree'</span><span class="pun">);</span><span class="pln"> plt</span><span class="pun">.</span><span class="pln">ylabel</span><span class="pun">(</span><span class="str">'rms error'</span><span class="pun">)</span></code></li><li class="L9"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">legend</span><span class="pun">();</span></code></li></ol></pre><p data-anchor-id="kdop"><img src="http://static.zybuluo.com/ronaldhan/dus7fgfsvnkeho8xv9poxkwd/output_53_0.png" alt="output_53_0.png-20.9kB" title=""> <br>
通过观察曲线，我们发现：</p><ul data-anchor-id="bf69">
<li>当模型复杂度较低时，训练误差和验证误差接近。这表明模型处于欠拟合状态，还没有具备足够的复杂度来表达数据。当前模型称为高偏差模型。</li>
<li>随着模型复杂度增长，训练误差和验证误差出现分离。这表明模型处于过拟合状态，过于复杂，拟合和数据中的噪声。当前模型称为高方差模型。</li>
<li>模型的训练得分几乎总是随着复杂度增长而提高，这是因为一个更复杂的模型能够拟合数据噪声，所以模型训练得分提高。</li>
</ul><p data-anchor-id="z0fr">从图中可以发现最佳自由度为4</p><div class="md-section-divider"></div><pre style="" data-anchor-id="4aen" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">model </span><span class="pun">=</span><span class="pln"> </span><span class="typ">PolynomialRegression</span><span class="pun">(</span><span class="lit">4</span><span class="pun">).</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">)</span></code></li><li class="L1"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">scatter</span><span class="pun">(</span><span class="pln">X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">)</span></code></li><li class="L2"><code class="language-python"><span class="pln">plt</span><span class="pun">.</span><span class="pln">plot</span><span class="pun">(</span><span class="pln">X_test</span><span class="pun">,</span><span class="pln"> model</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="pln">X_test</span><span class="pun">));</span></code></li></ol></pre><p data-anchor-id="273u"><img src="http://static.zybuluo.com/ronaldhan/4shrwhfp5ipd2gnrfpz5v3sx/output_55_0.png" alt="output_55_0.png-15.5kB" title=""></p><div class="md-section-divider"></div><h3 id="通过学习曲线来判断训练数据是否充足" data-anchor-id="cy2j">通过学习曲线来判断训练数据是否充足</h3><p data-anchor-id="1aun">偏差和方差之间的转折点高度依赖于训练数据的数量，通过使用学习曲线来确定转折点。具体方法是，绘制MSE随训练样本变化的曲线。</p><div class="md-section-divider"></div><pre style="" data-anchor-id="w2a8" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">learning_curve </span><span class="kwd">import</span><span class="pln"> learning_curve</span></code></li><li class="L1"><code class="language-python"></code></li><li class="L2"><code class="language-python"><span class="kwd">def</span><span class="pln"> plot_learning_curve</span><span class="pun">(</span><span class="pln">degree</span><span class="pun">=</span><span class="lit">3</span><span class="pun">):</span></code></li><li class="L3"><code class="language-python"><span class="pln">    train_sizes </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">linspace</span><span class="pun">(</span><span class="lit">0.05</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">20</span><span class="pun">)</span></code></li><li class="L4"><code class="language-python"><span class="pln">    N_train</span><span class="pun">,</span><span class="pln"> val_train</span><span class="pun">,</span><span class="pln"> val_test </span><span class="pun">=</span><span class="pln"> learning_curve</span><span class="pun">(</span><span class="typ">PolynomialRegression</span><span class="pun">(</span><span class="pln">degree</span><span class="pun">),</span><span class="pln"> X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">,</span><span class="pln"> train_sizes</span><span class="pun">,</span><span class="pln"> cv</span><span class="pun">=</span><span class="lit">5</span><span class="pun">,</span><span class="pln"> scoring</span><span class="pun">=</span><span class="pln">rms_error</span><span class="pun">)</span></code></li><li class="L5"><code class="language-python"><span class="pln">    plot_with_err</span><span class="pun">(</span><span class="pln">N_train</span><span class="pun">,</span><span class="pln"> val_train</span><span class="pun">,</span><span class="pln"> label</span><span class="pun">=</span><span class="str">'training scores'</span><span class="pun">)</span></code></li><li class="L6"><code class="language-python"><span class="pln">    plot_with_err</span><span class="pun">(</span><span class="pln">N_train</span><span class="pun">,</span><span class="pln"> val_test</span><span class="pun">,</span><span class="pln"> label</span><span class="pun">=</span><span class="str">'validation scores'</span><span class="pun">)</span></code></li><li class="L7"><code class="language-python"><span class="pln">    plt</span><span class="pun">.</span><span class="pln">xlabel</span><span class="pun">(</span><span class="str">'Training Set Size'</span><span class="pun">);</span><span class="pln"> plt</span><span class="pun">.</span><span class="pln">ylabel</span><span class="pun">(</span><span class="str">'rms error'</span><span class="pun">)</span></code></li><li class="L8"><code class="language-python"><span class="pln">    plt</span><span class="pun">.</span><span class="pln">ylim</span><span class="pun">(</span><span class="lit">0</span><span class="pun">,</span><span class="pln"> </span><span class="lit">3</span><span class="pun">)</span></code></li><li class="L9"><code class="language-python"><span class="pln">    plt</span><span class="pun">.</span><span class="pln">xlim</span><span class="pun">(</span><span class="lit">5</span><span class="pun">,</span><span class="pln"> </span><span class="lit">80</span><span class="pun">)</span></code></li><li class="L0"><code class="language-python"><span class="pln">    plt</span><span class="pun">.</span><span class="pln">legend</span><span class="pun">()</span></code></li><li class="L1"><code class="language-python"></code></li><li class="L2"><code class="language-python"><span class="pln">plot_learning_curve</span><span class="pun">(</span><span class="lit">1</span><span class="pun">)</span></code></li></ol></pre><p data-anchor-id="xd9g"><img src="http://static.zybuluo.com/ronaldhan/hermmk822h2malc9hx94891r/output_59_0.png" alt="output_59_0.png-20.9kB" title=""> <br>
曲线走势符合学习曲线的典型走势：当训练数据较少时，训练得分和验证得分差距较大，这表明模型处于<strong>过拟合</strong>状态；随着训练样本增加，训练得分和验证得分逐渐收敛，这表明模型可能处于<strong>欠拟合</strong>状态。 <br>
图中还显示，随着训练样本增加，训练得分不再增加，验证得分不再降低。要想进一步降低MSE，需要改变<span class="MathJax_Preview"></span><span aria-readonly="true" role="textbox" id="MathJax-Element-56-Frame" class="MathJax_SVG" style="font-size: 100%; display: inline-block;"><svg viewBox="0 -715.9033013280564 523.5 747.8066026561128" style="width: 1.222ex; height: 1.778ex; vertical-align: -0.222ex; margin: 1px 0px;" xmlns:xlink="http://www.w3.org/1999/xlink"><g transform="matrix(1 0 0 -1 0 0)" stroke-width="0" fill="black" stroke="black"><use xlink:href="#MJMATHI-64"></use></g></svg></span><script id="MathJax-Element-56" type="math/tex">d</script>的值。</p><div class="md-section-divider"></div><pre style="" data-anchor-id="jv7c" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">plot_learning_curve</span><span class="pun">(</span><span class="lit">3</span><span class="pun">)</span></code></li></ol></pre><p data-anchor-id="9co5"><img src="http://static.zybuluo.com/ronaldhan/e2wa3c3bny2j0sbwedn7t2sa/output_61_0.png" alt="output_61_0.png-20.8kB" title=""> <br>
通过曲线可以观察到，增加模型复杂度后，模型的MSE下降到了1.0. <br>
进一步增加复杂度会出现什么情况呢？</p><div class="md-section-divider"></div><pre style="" data-anchor-id="0ma5" class="prettyprint linenums prettyprinted"><ol class="linenums"><li class="L0"><code class="language-python"><span class="pln">plot_learning_curve</span><span class="pun">(</span><span class="lit">10</span><span class="pun">)</span></code></li></ol></pre><p data-anchor-id="xw2t"><img src="http://static.zybuluo.com/ronaldhan/sb9vaq636tg18d00m1sa4kc0/output_63_0.png" alt="output_63_0.png-20.3kB" title=""> <br>
对于这个更复杂的模型，训练得分和验证得分最终也会收敛，但收敛于较大的样本数。由此：</p><ul data-anchor-id="nn80">
<li>可以通过添加更多的采样点或者简化模型来使曲线收敛</li>
<li>只能通过增加模型复杂度来降低收敛误差 <br>
进一步：提升次优模型的方法：如果曲线将要收敛到一起，需要增加模型的复杂度；如果曲线是分离的，需要增加训练数据。</li>
</ul><div class="md-section-divider"></div><h3 id="总结" data-anchor-id="s21t">总结</h3><ul data-anchor-id="h0q9">
<li><strong>训练得分</strong>表示模型对训练数据集的拟合好坏，这个指标并不能很好的反应模型的质量。</li>
<li><strong>验证得分</strong>表示模型在验证数据集上的表现，最有效的方法是交叉验证。</li>
<li>验证曲线是训练得分和验证得分随<strong>模型复杂度</strong>变化曲线 <br>
<ul><li>当两条曲线距离很近，说明模型处于<strong>欠拟合</strong>状态</li>
<li>当两条曲线距离很远，说明模型处于<strong>过拟合</strong>状态</li>
<li>最优选择处于两者之间</li></ul></li>
<li>学习曲线是训练得分和验证得分随<strong>训练样本数量</strong>的变化曲线 <br>
<ul><li>当两条曲线距离很近，说明模型处于<strong>欠拟合</strong>状态，增加更多的数据并不能提高模型质量</li>
<li>当两条曲线距离很远，说明模型处于<strong>过拟合</strong>状态，增加更多的数据可以提高模型质量</li></ul></li>
</ul></div>
</body>
</html>